Experiment name: example_MLP

DSE of MNIST dataset:

	fc_batchnorm:	[True]
	updates:	['SGD']
	loss:	['categorical_crossentropy']
	out_activation:	['softmax']
	fc_depth:	[1 2 3]
	fc_layers:	[ 10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27
  29  30  31  32  34  35  36  38  39  41  43  44  46  48  50  52  54  56
  59  61  64  66  69  72  75  78  81  84  87  91  95  98 102 107 111 115
 120 125 130 135 141 146 152 158 165 172 178 186 193 201 209 218 226 235
 245 255 265 276 287 299 311 323 336 350 364 379 394 410 426 444 462 480
 499]
	epochs:	[10]
	out_batchnorm:	[True]
	learning_rate:	[ 0.001       0.00161199  0.00259853  0.00418881  0.00675234  0.01088473
  0.01754613  0.02828427  0.04559409  0.07349743  0.11847745  0.19098501
  0.30786678  0.4962796   0.80000001]
	fc_layers_local:	['fc_depth']
	fc_activation:	['ReLU', 'tanh']
	batchsize:	[200]
	fc_dropout:	[None]

Pareto-optimal results:
fc_layers: [287, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0128000307083, Cost: 331326.4976
fc_layers: [265, 299], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0144000315666, Cost: 292072.892
fc_layers: [209, 64, 480], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0148000228405, Cost: 214283.8144
fc_layers: [87, 172], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0164000451565, Cost: 85503.2224
fc_layers: [87, 91], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0177000296116, Cost: 77589.652
fc_layers: [66, 165], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.018400042057, Cost: 64746.8448
fc_layers: [72, 81], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0191000330448, Cost: 63544.248
fc_layers: [66, 32, 44], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0211000287533, Cost: 56105.0688
fc_layers: [48, 265], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0218000221252, Cost: 53383.6144
fc_layers: [59, 84, 11], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0218000340462, Cost: 52622.1712
fc_layers: [30, 165, 56], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.022200037241, Cost: 38545.544
fc_layers: [32, 75, 95], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0238000321388, Cost: 35819.0536
fc_layers: [34, 24], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0247000300884, Cost: 27911.5264
fc_layers: [29, 32, 35], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0255000376701, Cost: 25314.9648
fc_layers: [23, 95, 23], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0265000343323, Cost: 22794.9504
fc_layers: [24, 54, 16], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0270000267029, Cost: 21288.1792
fc_layers: [21, 125], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0279000329971, Cost: 20485.4408
fc_layers: [19, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0301000380516, Cost: 17018.6584
fc_layers: [16, 107], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.032700022459, Cost: 15436.3472
fc_layers: [15, 64], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0330000197887, Cost: 13456.192
fc_layers: [14, 39, 30], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0382000231743, Cost: 13085.5424
fc_layers: [11, 59, 38], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0385000193119, Cost: 11980.644
fc_layers: [12, 78], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0390000224113, Cost: 11204.0928
fc_layers: [11, 102], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0404000246525, Cost: 10843.5152
fc_layers: [12, 61], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0420000219345, Cost: 10827.4
fc_layers: [11, 64, 16], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0421000230312, Cost: 10587.6864
fc_layers: [11, 48, 13], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0427000188828, Cost: 9977.3232
fc_layers: [10, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0442000293732, Cost: 9286.384
fc_layers: [10, 39], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0444000303745, Cost: 8682.064
fc_layers: [10, 20], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.047100020647, Cost: 8299.328
fc_layers: [10, 17], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0528000092506, Cost: 8238.896
fc_layers: [10, 16], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0539000082016, Cost: 8218.752
fc_layers: [10, 14], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0543000149727, Cost: 8178.464
fc_layers: [10, 11], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0571000123024, Cost: 8118.032
fc_layers: [10, 10], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0575000178814, Cost: 8097.888
fc_layers: [10], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0590000140667, Cost: 7997.168

All results:
fc_layers: [52], learning_rate: 0.02828427031636238, fc_activation: tanh, Error: 0.0537000155449, Cost: 41585.2736
fc_layers: [95, 48, 21], learning_rate: 0.0010000000474974513, fc_activation: tanh, Error: 0.127900000811, Cost: 80835.8576
fc_layers: [10, 125, 16], learning_rate: 0.0025985264219343662, fc_activation: ReLU, Error: 0.107999995947, Cost: 11331.0
fc_layers: [32], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0401000237465, Cost: 25590.9376
fc_layers: [201, 36, 29], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.024800028801, Cost: 167350.3088
fc_layers: [18], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0545000088215, Cost: 14394.9024
fc_layers: [10, 25], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0542000079155, Cost: 8400.048
fc_layers: [115], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.027700022459, Cost: 91967.432
fc_layers: [17, 27], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0432000255585, Cost: 14158.2104
fc_layers: [38, 24], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0295000243187, Cost: 31166.7968
fc_layers: [25, 14], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0372000169754, Cost: 20234.648
fc_layers: [17], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0456000196934, Cost: 13595.1856
fc_layers: [245], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0313000333309, Cost: 195930.616
fc_layers: [135], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0264000248909, Cost: 107961.768
fc_layers: [10, 16], learning_rate: 0.02828427031636238, fc_activation: tanh, Error: 0.0708000063896, Cost: 8218.752
fc_layers: [13], learning_rate: 0.0025985264219343662, fc_activation: ReLU, Error: 0.117499995232, Cost: 10396.3184
fc_layers: [12], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0481000101566, Cost: 9596.6016
fc_layers: [30, 27], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0375000274181, Cost: 24777.12
fc_layers: [11, 15], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0548000097275, Cost: 9003.3608
fc_layers: [19], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0462000262737, Cost: 15194.6192
fc_layers: [107, 30, 115], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0194000327587, Cost: 92358.2256
fc_layers: [78, 81, 17], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0205000448227, Cost: 69513.9224
fc_layers: [26], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0412000286579, Cost: 20792.6368
fc_layers: [64], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.025200022459, Cost: 51181.8752
fc_layers: [13, 107], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0414000213146, Cost: 12744.1016
fc_layers: [81], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0223000431061, Cost: 64777.0608
fc_layers: [125, 32], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0258000230789, Cost: 103056.704
fc_layers: [11], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0590000104904, Cost: 8796.8848
fc_layers: [16], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0501000142097, Cost: 12795.4688
fc_layers: [245], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0224000179768, Cost: 195930.616
fc_layers: [17], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.046600022316, Cost: 13595.1856
fc_layers: [10], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0594000196457, Cost: 7997.168
fc_layers: [22, 64], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0309000205994, Cost: 19434.9312
fc_layers: [39, 30], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0297000288963, Cost: 32276.7312
fc_layers: [15], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0487000072002, Cost: 11995.752
fc_layers: [172], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0165000343323, Cost: 137551.2896
fc_layers: [193], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0203000283241, Cost: 154345.3424
fc_layers: [18, 69], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0363000202179, Cost: 16159.5168
fc_layers: [16, 41], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0350000333786, Cost: 13707.992
fc_layers: [201, 201], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0171000254154, Cost: 201434.964
fc_layers: [235], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0190000259876, Cost: 187933.448
fc_layers: [15, 44], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0387000286579, Cost: 12952.592
fc_layers: [22, 158, 81], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0275000357628, Cost: 34579.1904
fc_layers: [15, 141], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0369000315666, Cost: 15395.052
fc_layers: [11], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0638999986649, Cost: 8796.8848
fc_layers: [11, 16], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0500000298023, Cost: 9024.512
fc_layers: [31, 66, 54], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0260000300407, Cost: 30673.2688
fc_layers: [38, 24, 186], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0335000395775, Cost: 37294.6016
fc_layers: [64, 84, 75], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0254000365734, Cost: 63052.7344
fc_layers: [115, 39, 22], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0235000288486, Cost: 96412.2056
fc_layers: [75, 81, 35], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0199000370502, Cost: 68550.032
fc_layers: [54, 78], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0306000316143, Cost: 47668.7616
fc_layers: [87, 87], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0254000234604, Cost: 77198.8584
fc_layers: [107, 91, 75], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.019600020647, Cost: 101928.64
fc_layers: [35, 84, 141], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0253000283241, Cost: 43948.1648
fc_layers: [15, 14, 21], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0390000271797, Cost: 12563.8128
fc_layers: [20, 91], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.033200032711, Cost: 18542.552
fc_layers: [17, 64], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0356000339985, Cost: 15164.4032
fc_layers: [10], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.062700009346, Cost: 7997.168
fc_layers: [87, 54], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0197000312805, Cost: 73974.8112
fc_layers: [78], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0313000178337, Cost: 62377.9104
fc_layers: [10], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0646000003815, Cost: 7997.168
fc_layers: [11], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0632000041008, Cost: 8796.8848
fc_layers: [111, 75, 35], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0249000191689, Cost: 99031.9328
fc_layers: [10], learning_rate: 0.07349742949008942, fc_activation: tanh, Error: 0.0710000002384, Cost: 7997.168
fc_layers: [186, 61, 480], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0185000312328, Cost: 192627.0
fc_layers: [38], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0298000395298, Cost: 30389.2384
fc_layers: [84, 111, 27], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0212000262737, Cost: 79011.8184
fc_layers: [111, 29, 61], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0234000313282, Cost: 93288.8784
fc_layers: [52, 22, 34], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0232000303268, Cost: 43309.6
fc_layers: [141], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0246000230312, Cost: 112760.0688
fc_layers: [75, 10, 61], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0223000299931, Cost: 61207.544
fc_layers: [78, 61, 35], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0227000212669, Cost: 68887.444
fc_layers: [13, 59], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0431000244617, Cost: 11632.1528
fc_layers: [52, 95], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.024700037241, Cost: 46993.9376
fc_layers: [146], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0193000233173, Cost: 116758.6528
fc_layers: [130, 84, 13], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0196000289917, Cost: 114883.2464
fc_layers: [178], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0209000241756, Cost: 142349.5904
fc_layers: [10], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0633999979496, Cost: 7997.168
fc_layers: [11], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0558000123501, Cost: 8796.8848
fc_layers: [12, 35], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0534000015259, Cost: 10251.2816
fc_layers: [34, 24], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0247000300884, Cost: 27911.5264
fc_layers: [165, 15], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.024700024128, Cost: 132935.292
fc_layers: [11], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0613000023365, Cost: 8796.8848
fc_layers: [111, 172], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0194000267982, Cost: 108612.4192
fc_layers: [130, 30, 218], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0194000244141, Cost: 115364.688
fc_layers: [54, 152, 209], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0236000227928, Cost: 85009.6944
fc_layers: [125, 98, 141], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0181000339985, Cost: 126381.4416
fc_layers: [10], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0590000140667, Cost: 7997.168
fc_layers: [16, 107], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.032700022459, Cost: 15436.3472
fc_layers: [13, 78, 27], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0448000228405, Cost: 13679.7904
fc_layers: [52, 152, 394], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0192000174522, Cost: 113310.0
fc_layers: [56, 125, 43], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.024000043869, Cost: 57117.3048
fc_layers: [81, 95, 364], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0188000309467, Cost: 110206.8168
fc_layers: [115, 218, 31], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0217000186443, Cost: 123178.5456
fc_layers: [72, 56, 66], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0247000443935, Cost: 65302.8192
fc_layers: [165, 15, 75], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0212000238895, Cost: 134672.712
fc_layers: [75], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0239000308514, Cost: 59978.76
fc_layers: [13, 98], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0396000218391, Cost: 12535.6112
fc_layers: [12, 61], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0420000219345, Cost: 10827.4
fc_layers: [10, 59], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0490000224113, Cost: 9084.944
fc_layers: [11, 78], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0438000226021, Cost: 10335.8864
fc_layers: [111, 235], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0179000389576, Cost: 116290.3048
fc_layers: [11, 66, 16], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0429000270367, Cost: 10642.0752
fc_layers: [111, 135, 54], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0212000274658, Cost: 110629.8408
fc_layers: [125, 13, 52], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0221000170708, Cost: 101546.9112
fc_layers: [10], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0677000081539, Cost: 7997.168
fc_layers: [98], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0196000266075, Cost: 78372.2464
fc_layers: [35], learning_rate: 0.004188810475170612, fc_activation: ReLU, Error: 0.0837999939919, Cost: 27990.088
fc_layers: [66, 32, 44], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0211000287533, Cost: 56105.0688
fc_layers: [12, 130, 38], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0386000370979, Cost: 16405.2736
fc_layers: [48, 38, 11], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0305000245571, Cost: 40271.8848
fc_layers: [10, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0442000293732, Cost: 9286.384
fc_layers: [44, 78, 50], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.026900036335, Cost: 42632.7616
fc_layers: [64, 31, 41], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0246000337601, Cost: 54228.6552
fc_layers: [13, 84], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0426000285149, Cost: 12211.2928
fc_layers: [11, 59, 38], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0385000193119, Cost: 11980.644
fc_layers: [201, 11, 499], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0207000315189, Cost: 171499.9728
fc_layers: [95], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0215000450611, Cost: 75973.096
fc_layers: [12, 78], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0390000224113, Cost: 11204.0928
fc_layers: [11, 59], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0480000174046, Cost: 9934.0136
fc_layers: [31, 52, 14], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0283000314236, Cost: 26976.8448
fc_layers: [107, 72], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0216000413895, Cost: 92976.6464
fc_layers: [10, 54], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0512000119686, Cost: 8984.224
fc_layers: [10, 69], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0545000183582, Cost: 9286.384
fc_layers: [107, 102, 299], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0189000356197, Cost: 129213.688
fc_layers: [107, 218], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0167000222206, Cost: 110181.6368
fc_layers: [15, 107], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0387000095844, Cost: 14538.932
fc_layers: [84, 54, 107], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0229000270367, Cost: 77796.128
fc_layers: [10, 18, 41], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0473000359535, Cost: 9234.0096
fc_layers: [102, 26, 186], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0214000296593, Cost: 89959.0752
fc_layers: [10, 22, 25], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0522000157833, Cost: 8923.792
fc_layers: [201, 31, 394], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0181000351906, Cost: 181264.7768
fc_layers: [87, 56, 209], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0207000315189, Cost: 87499.4928
fc_layers: [81, 66, 36], learning_rate: 0.004188810475170612, fc_activation: ReLU, Error: 0.0650000047684, Cost: 72101.4192
fc_layers: [107, 255], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.019300018549, Cost: 114541.8056
fc_layers: [84, 14], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0223000264168, Cost: 67655.6384
fc_layers: [10, 152], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.046300008297, Cost: 10958.336
fc_layers: [32, 36], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0310000252724, Cost: 26791.52
fc_layers: [12, 66], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.044100022316, Cost: 10938.192
fc_layers: [10, 50], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0497000169754, Cost: 8903.648
fc_layers: [10, 35], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0528000116348, Cost: 8601.488
fc_layers: [10, 11], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0571000123024, Cost: 8118.032
fc_layers: [102, 218], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.01880002141, Cost: 105135.5648
fc_layers: [84, 130, 59], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.018900026083, Cost: 85648.2592
fc_layers: [29, 61, 26], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0295000350475, Cost: 26540.7272
fc_layers: [10, 50], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0504000127316, Cost: 8903.648
fc_layers: [32, 21], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0299000298977, Cost: 26156.984
fc_layers: [31, 35], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0277000403404, Cost: 25924.3208
fc_layers: [10, 31], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.051600022316, Cost: 8520.912
fc_layers: [84], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0236000359058, Cost: 67176.2112
fc_layers: [66], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0245000505447, Cost: 52781.3088
fc_layers: [75, 75], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0221000480652, Cost: 65644.26
fc_layers: [115, 66, 87], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0217000317574, Cost: 105113.4064
fc_layers: [91, 95, 186], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0223000276089, Cost: 100235.5368
fc_layers: [29, 39, 15], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0336000192165, Cost: 24779.1344
fc_layers: [72, 165], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0196000242233, Cost: 70481.8416
fc_layers: [61, 41, 13], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0260000360012, Cost: 51355.1136
fc_layers: [69, 158], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0233000385761, Cost: 67057.3616
fc_layers: [59, 84, 11], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0218000340462, Cost: 52622.1712
fc_layers: [95, 120, 107], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0219000351429, Cost: 100508.488
fc_layers: [56, 102], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0263000285625, Cost: 51000.5792
fc_layers: [91, 209], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.018800034523, Cost: 93118.6616
fc_layers: [48, 31], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0318000221252, Cost: 39713.896
fc_layers: [69, 141], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0224000203609, Cost: 65704.692
fc_layers: [91, 69], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0194000351429, Cost: 78876.8536
fc_layers: [10, 14], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.05650000453, Cost: 8178.464
fc_layers: [10, 125], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0463000249863, Cost: 10414.448
fc_layers: [95, 78], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0211000394821, Cost: 83265.224
fc_layers: [84, 95], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0212000203133, Cost: 75324.4592
fc_layers: [11, 87], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0487000226974, Cost: 10526.2472
fc_layers: [172, 15], learning_rate: 0.01088473480194807, fc_activation: ReLU, Error: 0.0412000083923, Cost: 138568.5616
fc_layers: [29, 32, 35], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0255000376701, Cost: 25314.9648
fc_layers: [10, 39], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0444000303745, Cost: 8682.064
fc_layers: [75, 152, 19], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0206000697613, Cost: 73805.6016
fc_layers: [87, 172], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0164000451565, Cost: 85503.2224
fc_layers: [87, 120], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0213000392914, Cost: 80422.9056
fc_layers: [10, 21], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0493000113964, Cost: 8319.472
fc_layers: [218, 158], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0213000285625, Cost: 208425.9392
fc_layers: [499], learning_rate: 0.01088473480194807, fc_activation: tanh, Error: 0.0569000065327, Cost: 399058.6832
fc_layers: [394, 17, 14], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0219000244141, Cost: 318246.9984
fc_layers: [462], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0251000201702, Cost: 369469.1616
fc_layers: [364], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0281000208855, Cost: 291096.9152
fc_layers: [84, 130], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0192000305653, Cost: 78638.1472
fc_layers: [394], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0209000253677, Cost: 315088.4192
fc_layers: [24, 48, 25], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0306000387669, Cost: 21572.2096
fc_layers: [12, 25, 14], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0435000252724, Cost: 10271.4256
fc_layers: [29, 24], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0310000312328, Cost: 23842.4384
fc_layers: [29, 38], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0296000289917, Cost: 24392.3696
fc_layers: [102], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0215000200272, Cost: 81571.1136
fc_layers: [323], learning_rate: 0.0010000000474974513, fc_activation: ReLU, Error: 0.104799975157, Cost: 258308.5264
fc_layers: [10, 12], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0633000051975, Cost: 8138.176
fc_layers: [25, 87, 21], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0291000378132, Cost: 23983.4464
fc_layers: [10, 20], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.047100020647, Cost: 8299.328
fc_layers: [41, 394], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0239000117779, Cost: 52614.1136
fc_layers: [25, 287, 43], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0242000162601, Cost: 39830.7312
fc_layers: [19, 95, 18], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0340000331402, Cost: 18724.8552
fc_layers: [43, 135], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0292000377178, Cost: 41161.2424
fc_layers: [56, 350], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0224000167847, Cost: 67486.4288
fc_layers: [21, 158], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0353000259399, Cost: 21515.8064
fc_layers: [13, 265], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0396000266075, Cost: 16404.2664
fc_layers: [394], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.02380002141, Cost: 315088.4192
fc_layers: [38, 311], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.024600019455, Cost: 45041.984
fc_layers: [59, 336], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0288000142574, Cost: 69939.968
fc_layers: [59, 299], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0220000302792, Cost: 67368.5864
fc_layers: [29, 245], learning_rate: 0.0025985264219343662, fc_activation: tanh, Error: 0.097899992466, Cost: 32523.4952
fc_layers: [10, 17], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0528000092506, Cost: 8238.896
fc_layers: [11, 64], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0467000210285, Cost: 10039.7696
fc_layers: [10, 120], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0515999984741, Cost: 10313.728
fc_layers: [27, 64], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0298000240326, Cost: 23705.4592
fc_layers: [36, 135, 107], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0245000445843, Cost: 48948.9128
fc_layers: [10, 19], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0567000102997, Cost: 8279.184
fc_layers: [78, 22, 75], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.022500025034, Cost: 65737.9296
fc_layers: [107, 43, 66], learning_rate: 0.07349742949008942, fc_activation: tanh, Error: 0.0355000150204, Cost: 92649.3064
fc_layers: [130, 61, 218], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0300000154972, Cost: 126230.3616
fc_layers: [102, 265, 209], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0235000264645, Cost: 165657.2056
fc_layers: [172, 24, 410], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0206000256538, Cost: 154016.9952
fc_layers: [10, 13], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.059399998188, Cost: 8158.32
fc_layers: [10, 14], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0618000054359, Cost: 8178.464
fc_layers: [10, 16], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0539000082016, Cost: 8218.752
fc_layers: [41, 115, 120], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0232000458241, Cost: 52232.3848
fc_layers: [111, 102], learning_rate: 0.07349742949008942, fc_activation: tanh, Error: 0.0295000195503, Cost: 100081.4352
fc_layers: [193, 245], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0215000247955, Cost: 202494.5384
fc_layers: [59, 323], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0277000212669, Cost: 69036.5096
fc_layers: [11, 72], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0431000185013, Cost: 10208.9792
fc_layers: [209, 323], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0232000231743, Cost: 236282.0696
fc_layers: [10, 10], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0641000008583, Cost: 8097.888
fc_layers: [201, 27, 178], learning_rate: 0.006752339657396078, fc_activation: tanh, Error: 0.061799993515, Cost: 170818.0984
fc_layers: [30, 16, 15], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0314000344276, Cost: 24565.608
fc_layers: [95, 17, 235], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0319000136852, Cost: 83033.568
fc_layers: [48, 323, 91], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0220000255108, Cost: 84039.7608
fc_layers: [87, 111], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0194000339508, Cost: 79543.62
fc_layers: [218, 31, 87], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0259000325203, Cost: 182541.9064
fc_layers: [78, 218], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0212000226974, Cost: 80914.4192
fc_layers: [81, 178], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0192000341415, Cost: 80275.8544
fc_layers: [95, 34], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.031700026989, Cost: 78611.96
fc_layers: [87, 336, 218], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.022900031805, Cost: 174112.6496
fc_layers: [81, 165], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0197000515461, Cost: 79084.3368
fc_layers: [84, 125], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0199000298977, Cost: 78164.7632
fc_layers: [107, 146, 209], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0245000231266, Cost: 133065.2208
fc_layers: [23, 24, 20], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0346000218391, Cost: 19402.7008
fc_layers: [350, 125], learning_rate: 0.02828427031636238, fc_activation: ReLU, Error: 0.025900015831, Cost: 321699.68
fc_layers: [172, 276, 32], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0207000243664, Cost: 192850.5984
fc_layers: [276, 444], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0175000321865, Cost: 345840.2496
fc_layers: [193, 379, 311], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0173000299931, Cost: 347925.1536
fc_layers: [193, 336, 226], learning_rate: 0.0016119945794343948, fc_activation: ReLU, Error: 0.0735999929905, Cost: 296475.3632
fc_layers: [115, 209, 29], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0224000287056, Cost: 121413.9312
fc_layers: [69, 111, 52], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0229000401497, Cost: 68536.9384
fc_layers: [22, 31, 11], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0337000250816, Cost: 18513.3432
fc_layers: [23, 95, 23], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0265000343323, Cost: 22794.9504
fc_layers: [186, 444, 31], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0213000202179, Cost: 244227.8704
fc_layers: [102, 394, 111], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0202000331879, Cost: 166188.0
fc_layers: [146, 265, 379], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0181000292301, Cost: 259232.1288
fc_layers: [158, 245], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0192000162601, Cost: 166220.2304
fc_layers: [186, 146, 13], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0206000256538, Cost: 176268.0576
fc_layers: [265, 336, 13], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0189000308514, Cost: 303467.3456
fc_layers: [287, 245], learning_rate: 0.07349742949008942, fc_activation: ReLU, Error: 0.0213000226021, Cost: 299916.9656
fc_layers: [265, 276], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0179000282288, Cost: 285702.352
fc_layers: [146, 193], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0187000274658, Cost: 145612.9184
fc_layers: [125, 87], learning_rate: 0.006752339657396078, fc_activation: ReLU, Error: 0.0541000068188, Cost: 110535.164
fc_layers: [78, 64, 24], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0223000442982, Cost: 68409.024
fc_layers: [19, 84, 31], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0362000286579, Cost: 19545.7232
fc_layers: [235, 209], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0191000247002, Cost: 237140.204
fc_layers: [226, 323, 44], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0160000360012, Cost: 266740.8048
fc_layers: [61, 426, 141], learning_rate: 0.0016119945794343948, fc_activation: tanh, Error: 0.0904999947548, Cost: 136260.0592
fc_layers: [52, 311], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0240000236034, Cost: 60482.36
fc_layers: [24, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0288000416756, Cost: 21314.3664
fc_layers: [125, 426, 209], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0185000288486, Cost: 244119.0928
fc_layers: [91, 111], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0181000292301, Cost: 83149.396
fc_layers: [20, 59], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0344000303745, Cost: 17575.64
fc_layers: [276, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0146000277996, Cost: 318762.6848
fc_layers: [22, 61], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0329000139236, Cost: 19338.24
fc_layers: [24, 54, 16], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0270000267029, Cost: 21288.1792
fc_layers: [218, 209, 41], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0254000151157, Cost: 227076.2616
fc_layers: [46, 276, 480], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0183000195026, Cost: 187379.488
fc_layers: [18, 125, 12], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0309000253677, Cost: 18111.4704
fc_layers: [95, 35], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0206000459194, Cost: 78717.716
fc_layers: [14, 64, 21], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0361000370979, Cost: 13522.6672
fc_layers: [44, 59, 69], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0250000405312, Cost: 42154.3416
fc_layers: [287, 364], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.014700024128, Cost: 335514.4352
fc_layers: [14, 44, 24], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0421000218391, Cost: 12980.7936
fc_layers: [15, 64], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0330000197887, Cost: 13456.192
fc_layers: [20, 52, 15], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0350000309944, Cost: 17777.08
fc_layers: [20, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0324000298977, Cost: 17877.8
fc_layers: [15, 61], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0419000196457, Cost: 13380.652
fc_layers: [87, 91], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0177000296116, Cost: 77589.652
fc_layers: [75, 75, 14], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0201000320911, Cost: 66087.428
fc_layers: [141, 130, 125], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0185000264645, Cost: 147427.8928
fc_layers: [50, 91, 84], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0234000337124, Cost: 52610.0848
fc_layers: [39, 44, 111], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0306000256538, Cost: 38561.6592
fc_layers: [141, 265], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0176000320911, Cost: 151643.0248
fc_layers: [46, 78, 125], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0230000329018, Cost: 51016.6944
fc_layers: [11, 48, 13], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0427000188828, Cost: 9977.3232
fc_layers: [14, 66, 16], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0417000329494, Cost: 13210.4352
fc_layers: [84, 115], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0198000299931, Cost: 77217.9952
fc_layers: [158, 172], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0217000246048, Cost: 153867.9296
fc_layers: [135, 245, 499], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0192000293732, Cost: 268076.352
fc_layers: [218, 350, 135], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0159000229836, Cost: 297941.8464
fc_layers: [235, 394], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0150000274181, Cost: 282791.544
fc_layers: [12, 66, 34], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.043400028944, Cost: 12876.0448
fc_layers: [209, 426, 287], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0166000318527, Cost: 380743.7584
fc_layers: [26, 265], learning_rate: 0.01754613406956196, fc_activation: tanh, Error: 0.0438000118732, Cost: 30139.4528
fc_layers: [35, 323], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.032500013113, Cost: 42277.22
fc_layers: [44, 255, 72], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0249000275135, Cost: 65262.5312
fc_layers: [36, 255, 91], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0273000347614, Cost: 61961.9368
fc_layers: [16], learning_rate: 0.004188810475170612, fc_activation: ReLU, Error: 0.0919999969006, Cost: 12795.4688
fc_layers: [50, 52, 107], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0265000414848, Cost: 48782.7248
fc_layers: [444, 29, 23], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0275000119209, Cost: 364474.4568
fc_layers: [11, 323], learning_rate: 0.01754613406956196, fc_activation: tanh, Error: 0.0490000116825, Cost: 15517.9304
fc_layers: [11, 69, 20], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0448000192642, Cost: 11041.9336
fc_layers: [10], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0662000012398, Cost: 7997.168
fc_layers: [24, 364], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0335000085831, Cost: 31416.5824
fc_layers: [15], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.050700019598, Cost: 11995.752
fc_layers: [287, 158], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0191000390053, Cost: 273891.9248
fc_layers: [186, 87], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0206000256538, Cost: 164048.7072
fc_layers: [172, 178, 115], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0190000236034, Cost: 188431.0048
fc_layers: [255, 152], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0195000231266, Cost: 241929.44
fc_layers: [193, 444, 311], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0151000285149, Cost: 380921.0256
fc_layers: [235, 462], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0157000350952, Cost: 299571.496
fc_layers: [323, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0177000355721, Cost: 372444.4304
fc_layers: [350], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0242000186443, Cost: 279900.88
fc_layers: [499], learning_rate: 0.02828427031636238, fc_activation: ReLU, Error: 0.0280000269413, Cost: 399058.6832
fc_layers: [426, 350], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0193000221252, Cost: 490087.4048
fc_layers: [410, 209], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0193000268936, Cost: 412166.384
fc_layers: [394, 299], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.017100032568, Cost: 432785.7824
fc_layers: [499, 201], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0169000267982, Cost: 497078.38
fc_layers: [11, 102], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0404000246525, Cost: 10843.5152
fc_layers: [125, 379], learning_rate: 0.01754613406956196, fc_activation: ReLU, Error: 0.0290000152588, Cost: 150238.988
fc_layers: [245, 499], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0156000363827, Cost: 321624.14
fc_layers: [480, 265, 38], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0171000254154, Cost: 517670.584
fc_layers: [480, 276, 20], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0174000179768, Cost: 518224.544
fc_layers: [218, 235], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0187000238895, Cost: 226108.3424
fc_layers: [499, 276], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0153000307083, Cost: 535528.24
fc_layers: [276], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0177000319958, Cost: 220721.8368
fc_layers: [226, 201], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0193000340462, Cost: 226237.264
fc_layers: [480, 16, 32], learning_rate: 0.04559409245848656, fc_activation: tanh, Error: 0.0356000125408, Cost: 387602.7904
fc_layers: [158, 218, 44], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0237000226974, Cost: 169560.1056
fc_layers: [287, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0128000307083, Cost: 331326.4976
fc_layers: [226, 265, 23], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0173000252247, Cost: 245151.4728
fc_layers: [31, 364], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0302000248432, Cost: 39510.4416
fc_layers: [48], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0348000323772, Cost: 38386.4064
fc_layers: [31, 115, 43], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0288000261784, Cost: 33483.3568
fc_layers: [265, 299], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0144000315666, Cost: 292072.892
fc_layers: [265, 276], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0157000279427, Cost: 285702.352
fc_layers: [11, 32, 17], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0482000231743, Cost: 9759.768
fc_layers: [15, 36], learning_rate: 0.0016119945794343948, fc_activation: tanh, Error: 0.121200008392, Cost: 12751.152
fc_layers: [13, 125], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0409000194073, Cost: 13161.0824
fc_layers: [44, 146, 59], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0261000227928, Cost: 50484.8928
fc_layers: [22, 91, 18], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0314000236988, Cost: 21219.6896
fc_layers: [444], learning_rate: 0.0010000000474974513, fc_activation: tanh, Error: 0.12239998579, Cost: 355074.2592
fc_layers: [10, 102], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0476000261307, Cost: 9951.136
fc_layers: [172, 193], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0235000252724, Cost: 171197.8128
fc_layers: [152, 218, 186], learning_rate: 0.04559409245848656, fc_activation: ReLU, Error: 0.0222000277042, Cost: 196113.9264
fc_layers: [87, 120, 15], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0201000475883, Cost: 81178.3056
fc_layers: [75, 72], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0193000471592, Cost: 65387.424
fc_layers: [218, 125, 19], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0189000296593, Cost: 202172.2344
fc_layers: [10, 12], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0590000104904, Cost: 8138.176
fc_layers: [499, 87, 11], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0219000279903, Cost: 438833.0112
fc_layers: [78, 75, 111], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0297000253201, Cost: 76987.3464
fc_layers: [218, 135], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0186000335217, Cost: 203144.1824
fc_layers: [158, 158, 125], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0220000255108, Cost: 171058.8192
fc_layers: [19, 226, 15], learning_rate: 0.04559409245848656, fc_activation: tanh, Error: 0.0395000207424, Cost: 22893.656
fc_layers: [130, 201], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0184000241756, Cost: 130996.432
fc_layers: [87, 81], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0215000391006, Cost: 76612.668
fc_layers: [41], learning_rate: 0.0025985264219343662, fc_activation: ReLU, Error: 0.0972000086308, Cost: 32788.3888
fc_layers: [255], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0262000215054, Cost: 203927.784
fc_layers: [48, 115, 41], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0286000263691, Cost: 48624.5944
fc_layers: [218, 323, 52], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0200000321865, Cost: 260504.2224
fc_layers: [130, 34], learning_rate: 0.49627959728240967, fc_activation: tanh, Error: 0.0264000070095, Cost: 107448.096
fc_layers: [120], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0199000489712, Cost: 95966.016
fc_layers: [235, 364], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0156000363827, Cost: 275388.624
fc_layers: [50, 115, 158], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0206000423431, Cost: 65165.84
fc_layers: [193, 178, 158], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0199000287056, Cost: 216920.664
fc_layers: [75, 226, 499], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0182000255585, Cost: 194907.3008
fc_layers: [235, 209, 107], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0168000233173, Cost: 258636.8736
fc_layers: [209, 125, 14], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0191000235081, Cost: 193252.4712
fc_layers: [22, 54], learning_rate: 0.0016119945794343948, fc_activation: ReLU, Error: 0.12120000124, Cost: 19112.6272
fc_layers: [287], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0199000310898, Cost: 229518.7216
fc_layers: [276], learning_rate: 0.01754613406956196, fc_activation: ReLU, Error: 0.0334000086784, Cost: 220721.8368
fc_layers: [152, 15, 158], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0221000242233, Cost: 126300.8656
fc_layers: [350, 38, 186], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0249000263214, Cost: 298763.7216
fc_layers: [32, 75, 95], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0238000321388, Cost: 35819.0536
fc_layers: [46, 72, 75], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0262000381947, Cost: 45853.7872
fc_layers: [21, 107, 18], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0304000115395, Cost: 20966.8824
fc_layers: [50, 107, 165], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0240000331402, Cost: 64314.756
fc_layers: [50, 61, 130], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0231000316143, Cost: 51850.656
fc_layers: [18, 64, 25], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0338000357151, Cost: 17237.2208
fc_layers: [21, 125], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0279000329971, Cost: 20485.4408
fc_layers: [323, 23], learning_rate: 0.02828427031636238, fc_activation: ReLU, Error: 0.0272000181675, Cost: 262769.4152
fc_layers: [141, 29], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0209000253677, Cost: 115750.4456
fc_layers: [209, 135, 146], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0190000331402, Cost: 214776.3352
fc_layers: [235, 91, 10], learning_rate: 0.02828427031636238, fc_activation: ReLU, Error: 0.0284000134468, Cost: 208122.772
fc_layers: [245, 218], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0166000294685, Cost: 249453.224
fc_layers: [64, 54, 152], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0224000310898, Cost: 63816.192
fc_layers: [41, 146, 98], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0232000291348, Cost: 53802.6096
fc_layers: [48, 95, 115], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0273000335693, Cost: 54657.7224
fc_layers: [141, 226, 226], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0223000252247, Cost: 197155.3712
fc_layers: [255, 209, 64], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0208000230789, Cost: 269155.0632
fc_layers: [21, 102], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0310000264645, Cost: 19767.3072
fc_layers: [41, 130, 98], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0227000427246, Cost: 51562.5968
fc_layers: [209, 186, 146], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0190000331402, Cost: 233011.6912
fc_layers: [30, 165, 56], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.022200037241, Cost: 38545.544
fc_layers: [135], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0239000248909, Cost: 107961.768
fc_layers: [91, 20, 287], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0209000229836, Cost: 82362.7728
fc_layers: [218, 226, 64], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.016000020504, Cost: 236978.0448
fc_layers: [25, 152, 61], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.028000023365, Cost: 33521.6304
fc_layers: [66, 165], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.018400042057, Cost: 64746.8448
fc_layers: [152, 410, 323], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0187000286579, Cost: 319431.4656
fc_layers: [72, 218, 444], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0211000335217, Cost: 174624.3072
fc_layers: [209, 165, 141], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0185000276566, Cost: 224621.7152
fc_layers: [209, 20, 426], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0182000267506, Cost: 182117.8752
fc_layers: [499, 276, 255], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0198000383377, Cost: 606203.464
fc_layers: [11, 22, 46], learning_rate: 0.07349742949008942, fc_activation: ReLU, Error: 0.0447000110149, Cost: 10412.4336
fc_layers: [41, 35, 158], learning_rate: 0.04559409245848656, fc_activation: ReLU, Error: 0.0296000468731, Cost: 40981.9608
fc_layers: [111, 20, 299], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0269000136852, Cost: 98921.1408
fc_layers: [111, 22, 226], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.020200022459, Cost: 97394.2256
fc_layers: [46, 10, 201], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0297000217438, Cost: 40835.9168
fc_layers: [20, 135], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0351000237465, Cost: 19872.056
fc_layers: [14, 10, 41], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0465000188351, Cost: 12021.9392
fc_layers: [14, 12, 75], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0450000178814, Cost: 12886.1168
fc_layers: [10, 10], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0575000178814, Cost: 8097.888
fc_layers: [311, 311], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0139000296593, Cost: 346129.316
fc_layers: [12, 21, 27], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0463000237942, Cost: 10572.5784
fc_layers: [193, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0157000243664, Cost: 223963.0064
fc_layers: [10, 13], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.068700016737, Cost: 8158.32
fc_layers: [75, 299, 480], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0172000253201, Cost: 231197.724
fc_layers: [10, 336, 444], learning_rate: 0.02828427031636238, fc_activation: tanh, Error: 0.0508000040054, Cost: 166010.7328
fc_layers: [115, 15, 462], learning_rate: 0.01754613406956196, fc_activation: tanh, Error: 0.0464000022411, Cost: 104179.732
fc_layers: [14, 39, 30], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0382000231743, Cost: 13085.5424
fc_layers: [10, 14], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0543000149727, Cost: 8178.464
fc_layers: [13, 66, 26], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0435000157356, Cost: 13119.7872
fc_layers: [499, 379, 394], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0169000327587, Cost: 738884.9416
fc_layers: [499, 410, 462], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0199000227451, Cost: 795532.8912
fc_layers: [226, 350], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0163000357151, Cost: 261654.4448
fc_layers: [178, 394, 499], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0219000315666, Cost: 414241.216
fc_layers: [19, 323], learning_rate: 0.004188810475170612, fc_activation: tanh, Error: 0.0726000022888, Cost: 24437.6936
fc_layers: [172, 178, 287], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0259000182152, Cost: 220999.824
fc_layers: [178, 87], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0215000247955, Cost: 157030.5376
fc_layers: [499], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0263000202179, Cost: 399058.6832
fc_layers: [480, 245], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.014900033474, Cost: 499943.864
fc_layers: [146, 480, 287], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0181000304222, Cost: 327515.2528
fc_layers: [265, 235], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.019100022316, Cost: 274346.172
fc_layers: [499, 410, 462], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0154000413418, Cost: 795532.8912
fc_layers: [499], learning_rate: 0.0016119945794343948, fc_activation: ReLU, Error: 0.0816999948025, Cost: 399058.6832
fc_layers: [287, 276], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0171000337601, Cost: 309190.256
fc_layers: [201, 165, 299], learning_rate: 0.01088473480194807, fc_activation: ReLU, Error: 0.0370000100136, Cost: 244824.1328
fc_layers: [64, 20, 410], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0254000282288, Cost: 64215.0432
fc_layers: [146, 245, 235], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0220000195503, Cost: 211672.1448
fc_layers: [152, 98, 364], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0258000171185, Cost: 174624.3072
fc_layers: [165, 50, 218], learning_rate: 0.07349742949008942, fc_activation: ReLU, Error: 0.0201000201702, Cost: 151774.968
fc_layers: [172, 235, 379], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.017900031805, Cost: 270053.4856
fc_layers: [350, 10, 265], learning_rate: 0.0025985264219343662, fc_activation: ReLU, Error: 0.0672999942303, Cost: 285239.04
fc_layers: [152, 18, 201], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0232000207901, Cost: 128450.2304
fc_layers: [10, 18], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0590000104904, Cost: 8259.04
fc_layers: [66, 11, 226], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0264000320435, Cost: 57627.9552
fc_layers: [158], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0220000314713, Cost: 126355.2544
fc_layers: [31, 364], learning_rate: 0.04559409245848656, fc_activation: ReLU, Error: 0.0297000217438, Cost: 39510.4416
fc_layers: [19, 69], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0301000380516, Cost: 17018.6584
fc_layers: [69, 265], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0202000200748, Cost: 75571.2232
fc_layers: [59, 226], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0213000285625, Cost: 62295.32
fc_layers: [48, 265], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0218000221252, Cost: 53383.6144
fc_layers: [66, 265], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0252000296116, Cost: 72401.5648
fc_layers: [43, 72, 10], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0290000355244, Cost: 37898.9216
fc_layers: [66, 158], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0235000526905, Cost: 64211.0144
fc_layers: [41, 43, 29], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0313000333309, Cost: 35699.1968
fc_layers: [480, 14, 102], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0323000121117, Cost: 388263.5136
fc_layers: [56, 276], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0243000233173, Cost: 62567.264
fc_layers: [209, 64, 480], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0148000228405, Cost: 214283.8144
fc_layers: [172, 10, 394], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0213000166416, Cost: 145488.0256
fc_layers: [209, 98, 178], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0179000258446, Cost: 205027.6464
fc_layers: [72, 18, 218], learning_rate: 0.07349742949008942, fc_activation: ReLU, Error: 0.0280000329018, Cost: 64307.7056
fc_layers: [111, 462], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0181000196934, Cost: 143955.0672
fc_layers: [69, 323, 16], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0222000300884, Cost: 82299.3192
fc_layers: [56, 299], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0210000264645, Cost: 64096.1936
fc_layers: [54, 499], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0210000300407, Cost: 74806.7584
fc_layers: [499, 480, 394], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0183000254631, Cost: 829727.3312
fc_layers: [499], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.016500030756, Cost: 399058.6832
fc_layers: [87, 87], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0205000376701, Cost: 77198.8584
fc_layers: [10, 66, 46], learning_rate: 0.30786678194999695, fc_activation: tanh, Error: 0.0482000172138, Cost: 12082.3712
fc_layers: [193, 178], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0189000296593, Cost: 188795.6112
fc_layers: [245, 245, 17], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0176000261307, Cost: 258286.368
fc_layers: [379, 444, 480], learning_rate: 0.19098500907421112, fc_activation: tanh, Error: 0.0187000238895, Cost: 688251.9904
fc_layers: [311, 299], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0158000278473, Cost: 342249.5816
fc_layers: [499, 218], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0134000301361, Cost: 505793.6816
fc_layers: [480, 186, 218], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.016100025177, Cost: 511987.9616
fc_layers: [218, 130, 95], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.020800024271, Cost: 214082.3744
fc_layers: [64, 172], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0214000117779, Cost: 63356.9088
fc_layers: [48, 311], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.02640001297, Cost: 56070.824
fc_layers: [499, 152, 107], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.0220000243187, Cost: 487885.6656
fc_layers: [72, 81], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0191000330448, Cost: 63544.248
fc_layers: [158, 25, 299], learning_rate: 0.02828427031636238, fc_activation: ReLU, Error: 0.0298000180721, Cost: 139282.6664
fc_layers: [64, 226, 78], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.021000033617, Cost: 83645.9456
fc_layers: [172, 394, 311], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.01630002141, Cost: 330623.472
fc_layers: [15, 25, 14], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0412000095844, Cost: 12715.9
fc_layers: [209, 14, 379], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0230000221729, Cost: 177144.3216
fc_layers: [499, 102, 16], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0192000234127, Cost: 447102.1232
fc_layers: [61, 59, 146], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0219000446796, Cost: 61939.7784
fc_layers: [193, 115, 480], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0167000246048, Cost: 235188.2504
fc_layers: [499, 235], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0133000326157, Cost: 514508.9832
fc_layers: [193, 165], learning_rate: 0.11847744882106781, fc_activation: tanh, Error: 0.0256000125408, Cost: 186137.6104
fc_layers: [20, 30, 15], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0355000281334, Cost: 17001.536
fc_layers: [172, 499, 125], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0161000299454, Cost: 286347.9672
fc_layers: [11, 12, 52], learning_rate: 0.11847744882106781, fc_activation: ReLU, Error: 0.051500030756, Cost: 9971.28
fc_layers: [43, 130, 59], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0256000375748, Cost: 47904.4464
fc_layers: [102, 276, 54], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0233000218868, Cost: 124453.6608
fc_layers: [29, 350], learning_rate: 0.07349742949008942, fc_activation: ReLU, Error: 0.0270000231266, Cost: 36647.9792
fc_layers: [235, 201, 52], learning_rate: 0.19098500907421112, fc_activation: ReLU, Error: 0.0204000270367, Cost: 244192.6184
fc_layers: [11, 64, 16], learning_rate: 0.800000011920929, fc_activation: ReLU, Error: 0.0421000230312, Cost: 10587.6864
fc_layers: [34, 102, 48], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0257000219822, Cost: 35755.6
fc_layers: [499, 410], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0144000387192, Cost: 604225.3232
fc_layers: [218, 245], learning_rate: 0.800000011920929, fc_activation: tanh, Error: 0.0236000263691, Cost: 228404.7584
fc_layers: [276, 276], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0170000386238, Cost: 297446.304
fc_layers: [265, 265], learning_rate: 0.49627959728240967, fc_activation: ReLU, Error: 0.0161000287533, Cost: 282655.572
fc_layers: [172, 426, 245], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0164000332355, Cost: 317207.568
fc_layers: [13, 35, 95], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.040300014019, Cost: 15029.4384
fc_layers: [172, 186, 72], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0186000263691, Cost: 182254.8544
fc_layers: [444], learning_rate: 0.004188810475170612, fc_activation: ReLU, Error: 0.0544000053406, Cost: 355074.2592
fc_layers: [499, 172, 18], learning_rate: 0.30786678194999695, fc_activation: ReLU, Error: 0.0174000191689, Cost: 483778.304
fc_layers: [27, 32], learning_rate: 0.04559409245848656, fc_activation: ReLU, Error: 0.0385000324249, Cost: 22512.9344
fc_layers: [87, 444], learning_rate: 0.04559409245848656, fc_activation: ReLU, Error: 0.025000026226, Cost: 112077.1872
